import pandas as pd
import numpy as np

from sqlalchemy import create_engine

import sqlalchemy
import psycopg2
import json

# read redshift connection credentials
with open("C:\\Users\\arul.francis\\Desktop\\mystuff\\creds\\redshift_creds.json") as fh:
    creds = json.load(fh)

# define redshift connection string
connstr = 'redshift+psycopg2://' + \
                creds['user_name'] + ':' + creds['password'] + '@' + \
                creds['host_name'] + ':' + creds['port_num'] + '/' + creds['db_name'];

def load_csv(filename):
    pathname = "C:\\Users\\arul.francis\\Documents\\metadata_tables\\src_files\\src_files_iter_4\\"
    fullfilename = pathname + filename + ".csv"
    # read up to 13 cols :: there's one filler
    df0 = pd.read_csv(fullfilename, skiprows=1, na_values=None, usecols=np.arange(13) )
    return df0              
    
def apply_header(df_in):
    # use this for dims
    header_col_list = ['field_name', 'data_type', 'natural_key', 'scd', 'notes', 'filler', 'source_alias', 'source_field_name', 'source_data_type', 'source_transformation', 'source_default_value', 'source_sample_value', 'source_notes']
    df_in.columns = header_col_list
    # add a col to hold the object name
    df_in['object_name'] = filename
    return df_in


def massage_df_conv_dtype(df_in):
    # convert col "scd" to type integer
    df_in['scd'] = df_in['scd'].fillna(0).astype(int)
    # convert natural_key to type boolean
    df_in['natural_key'] = df_in['natural_key'].fillna(False).astype('bool')
    return df_in

def massage_df_drop_cols_rows(df_in):
    # drop the blank column called filler 
    df_in_col_rmvd = df_in.drop(['filler'], axis=1)
    
    # if the first col fieldname is null drop the row
    df_in_col_rmvd = df_in_col_rmvd.dropna(axis=0, subset=['field_name'])

    # convert NaN's to empty string
    df_in_col_rmvd = df_in_col_rmvd.fillna('')
    return df_in_col_rmvd

def write_df_to_db(df_in):
    # create engine using redshift connection string
    engine = create_engine(connstr)
    # insert to table "staging.meta_object_stm" .. append data
    df_in.to_sql('meta_object_stm',  engine, index=False, schema='staging', if_exists='append', chunksize=1000)

# check row count and col count
df4.shape

filename = 'd_deployment_status'
df1 = load_csv(filename)
df2 = apply_header(df1)

df3 = massage_df_conv_dtype(df2)
df4 = massage_df_drop_cols_rows(df3)

write_df_to_db(df4)                          
